{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Josue\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2785: DtypeWarning: Columns (1,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_csv(\"Building_Permits.csv\")\n",
    "data2 = pd.read_csv(\"Libraries_-_Locations__Hours_and_Contact_Information_-_Map.csv\")\n",
    "data3 = pd.read_csv(\"Green_Roofs_-_Map.csv\")\n",
    "data4 = pd.read_csv(\"Chicago_Park_District__Movies_in_the_Parks_2017.csv\")\n",
    "data5 = pd.read_csv(\"Towed_Vehicles.csv\")\n",
    "data6 = pd.read_csv(\"Public_Health_Department_Events_-_For_LGBTQ.csv\")\n",
    "# data.head()\n",
    "# data.info\n",
    "dfs = [data1[0:500],data2,data3,data4,data5,data6]\n",
    "# dfs = [data1[0:5],data2[0:5],data3[0:5],data4[0:5],data5[0:5],data6[0:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 131)\n",
      "(80, 11)\n",
      "(103, 15)\n",
      "(237, 10)\n",
      "(5002, 10)\n",
      "(64, 9)\n",
      "ID                          int64\n",
      "PERMIT#                    object\n",
      "  PERMIT_TYPE              object\n",
      "         ISSUE_DATE        object\n",
      "        ESTIMATED_COST    float64\n",
      "         AMOUNT_WAIVED    float64\n",
      "   AMOUNT_PAID            float64\n",
      "    TOTAL_FEE             float64\n",
      "STREET_NUMBER               int64\n",
      "STREET DIRECTION           object\n",
      "STREET_NAME                object\n",
      "  SUFFIX                   object\n",
      "WORK_DESCRIPTION           object\n",
      "   PIN1                    object\n",
      "   PIN2                    object\n",
      "  PIN3                     object\n",
      "  PIN4                     object\n",
      " PIN5                      object\n",
      " PIN6                      object\n",
      " PIN7                      object\n",
      " PIN8                      object\n",
      " PIN9                      object\n",
      "     PIN10                 object\n",
      "CONTRACTOR_1_TYPE          object\n",
      "CONTRACTOR_1_NAME          object\n",
      "CONTRACTOR_1_ADDRESS       object\n",
      "CONTRACTOR_1_CITY          object\n",
      "CONTRACTOR_1_STATE         object\n",
      "CONTRACTOR_1_ZIPCODE       object\n",
      "CONTRACTOR_1_PHONE         object\n",
      "                           ...   \n",
      "CONTRACTOR_12_NAME         object\n",
      "CONTRACTOR_12_ADDRESS      object\n",
      "CONTRACTOR_12_CITY         object\n",
      "CONTRACTOR_12_STATE        object\n",
      "CONTRACTOR_12_ZIPCODE      object\n",
      "CONTRACTOR_12_PHONE        object\n",
      "CONTRACTOR_13_TYPE         object\n",
      "CONTRACTOR_13_NAME         object\n",
      "CONTRACTOR_13_ADDRESS      object\n",
      "CONTRACTOR_13_CITY         object\n",
      "CONTRACTOR_13_STATE        object\n",
      "CONTRACTOR_13_ZIPCODE      object\n",
      "CONTRACTOR_13_PHONE        object\n",
      "CONTRACTOR_14_TYPE         object\n",
      "CONTRACTOR_14_NAME         object\n",
      "CONTRACTOR_14_ADDRESS      object\n",
      "CONTRACTOR_14_CITY         object\n",
      "CONTRACTOR_14_STATE        object\n",
      "CONTRACTOR_14_ZIPCODE      object\n",
      "CONTRACTOR_14_PHONE        object\n",
      "CONTRACTOR_15_TYPE         object\n",
      "CONTRACTOR_15_NAME         object\n",
      "CONTRACTOR_15_ADDRESS      object\n",
      "CONTRACTOR_15_CITY         object\n",
      "CONTRACTOR_15_STATE        object\n",
      "CONTRACTOR_15_ZIPCODE     float64\n",
      "CONTRACTOR_15_PHONE       float64\n",
      "LATITUDE                  float64\n",
      "LONGITUDE                 float64\n",
      "LOCATION                   object\n",
      "Length: 131, dtype: object\n",
      "*****************\n",
      "NAME                      object\n",
      "HOURS OF OPERATION        object\n",
      "CYBERNAVIGATOR            object\n",
      "TEACHER IN THE LIBRARY    object\n",
      "ADDRESS                   object\n",
      "CITY                      object\n",
      "STATE                     object\n",
      "ZIP                        int64\n",
      "PHONE                     object\n",
      "WEBSITE                   object\n",
      "LOCATION                  object\n",
      "dtype: object\n",
      "*****************\n",
      "ID                      int64\n",
      "HOUSE_NUMBER            int64\n",
      "PRE_DIR                object\n",
      "STREET_NAME            object\n",
      "STREET_TYPE            object\n",
      "FULL_ADDRESS_RANGE     object\n",
      "BUILDING_NAME1         object\n",
      "BUILDING_NAME2         object\n",
      "MONTH_VIEW             object\n",
      "TOTAL_ROOF_SQFT         int64\n",
      "VEGETATED_SQFT          int64\n",
      "FACT_SHEET             object\n",
      "LATITUDE              float64\n",
      "LONGITUDE             float64\n",
      "LOCATION               object\n",
      "dtype: object\n",
      "*****************\n",
      "Day             object\n",
      "Date            object\n",
      "Park            object\n",
      "Park Phone      object\n",
      "Title           object\n",
      "CC              object\n",
      "Rating          object\n",
      "Underwriter     object\n",
      "Park Address    object\n",
      "Location        object\n",
      "dtype: object\n",
      "*****************\n",
      "Tow Date              object\n",
      "Make                  object\n",
      "Style                 object\n",
      "Model                 object\n",
      "Color                 object\n",
      "Plate                 object\n",
      "State                 object\n",
      "Towed to Address      object\n",
      "Tow Facility Phone    object\n",
      "Inventory Number       int64\n",
      "dtype: object\n",
      "*****************\n"
     ]
    }
   ],
   "source": [
    "print(data1[0:50000].shape)\n",
    "print(data2.shape)\n",
    "print(data3.shape)\n",
    "print(data4.shape)\n",
    "print(data5.shape)\n",
    "print(data6.shape)\n",
    "i = 0\n",
    "while i < 5:\n",
    "    print(dfs[i].dtypes)\n",
    "    print(\"*****************\")\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# month = []\n",
    "# day = []\n",
    "# year = []\n",
    "\n",
    "# for index, row in data.iterrows():\n",
    "\n",
    "# #     if i == 4:\n",
    "# #         break\n",
    "# #     print(row[3].split(\"/\"))\n",
    "#     date = row[3]\n",
    "# #     print(date)\n",
    "#     i = i + 1\n",
    "#     month.append(date[0])\n",
    "#     day.append(date[1])\n",
    "#     year.append(date[2])\n",
    "    \n",
    "\n",
    "# data[\"Month\"] = month\n",
    "# data[\"Day\"] = day\n",
    "# data[\"Year\"]= year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test, y_train, y_test = train_test_split(,test_size=0.25, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['11/1/2012']\n",
      "None\n",
      "['/', '/', '#$%']\n",
      "#\n",
      "['*', '*', '*', '/', '/', '/', '/']\n"
     ]
    }
   ],
   "source": [
    "#Sample data for comparison and helper functions for suffix tree\n",
    "regexArr = [\"^[\\d]{1,2}-[\\d]{1,2}-[\\d]{4}$\"]\n",
    "yearArr = []\n",
    "monthArr = []\n",
    "dayArr = []\n",
    "year = 50\n",
    "inc = 1\n",
    "while year > 0 :\n",
    "    yearArr.append(2018 - year)\n",
    "    year = year - 1\n",
    "while inc < 32:\n",
    "    if(inc < 13):\n",
    "        monthArr.append(inc)\n",
    "    dayArr.append(inc)\n",
    "    inc = inc + 1\n",
    "    \n",
    "# print(regexArr[0])\n",
    "myVar = \"11/1/2012\"\n",
    "print(myVar.split('\\W+'))\n",
    "match = re.match(\"^[\\d]{1,2}/[\\d]{1,2}/[\\d]{4}$\", \"1/12/2018 06:00:00 PM\")\n",
    "print(match)\n",
    "if match is not None:\n",
    "    print(match)\n",
    "    print(\"yay!\")\n",
    "nonAlpha = re.findall('\\W+', \"11/1/201#$%2\")\n",
    "print(nonAlpha)\n",
    "\n",
    "#Functions to help parse and splitting\n",
    "def leastFrequent(arr, n) : \n",
    "  \n",
    "    # Sort the array \n",
    "    arr.sort() \n",
    "   \n",
    "    # find the min frequency using \n",
    "    # linear traversal \n",
    "    min_count = n + 1\n",
    "    res = -1\n",
    "    curr_count = 1\n",
    "    for i in range(1, n) : \n",
    "        if (arr[i] == arr[i - 1]) : \n",
    "            curr_count = curr_count + 1\n",
    "        else : \n",
    "            if (curr_count < min_count) : \n",
    "                min_count = curr_count \n",
    "                res = arr[i - 1] \n",
    "              \n",
    "            curr_count = 1\n",
    "              \n",
    "    \n",
    "    # If last element is least frequent \n",
    "    if (curr_count < min_count) : \n",
    "        min_count = curr_count \n",
    "        res = arr[n - 1] \n",
    "      \n",
    "    return res \n",
    "      \n",
    "   \n",
    " \n",
    "arr = ['*', '*', '/', '/', '/', '/', '*', '#'] \n",
    "n = len(arr) \n",
    "print(leastFrequent(arr, n)) \n",
    "\n",
    "def remAll(L, item):\n",
    "    answer = []\n",
    "    for i in L:\n",
    "        if i!=item:\n",
    "            answer.append(i)\n",
    "    return answer\n",
    "\n",
    "print(remAll(arr, leastFrequent(arr,n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Josue\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:177: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Josue\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Josue\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:179: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Josue\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:180: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Josue\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:181: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Josue\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:182: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "**********\n",
      "**********\n",
      "**********\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "#algorithm for searching for temporal information\n",
    "# predMonArr = []\n",
    "# predDayArr = []\n",
    "# predYearArr = []\n",
    "# predHourArr = []\n",
    "# predMinArr = []\n",
    "# predSecArr = []\n",
    "\n",
    "i = 0\n",
    "while i < len(dfs):\n",
    "    print(\"**********\")\n",
    "    predMonArr = []\n",
    "    predDayArr = []\n",
    "    predYearArr = []\n",
    "    predHourArr = []\n",
    "    predMinArr = []\n",
    "    predSecArr = []\n",
    "    df = dfs[i]\n",
    "    j = 0\n",
    "    colNames = df.columns.values\n",
    "#     print(colNames)\n",
    "    for index, row in df.iterrows():\n",
    "#         print(index, row)\n",
    "#         print(\"***\", index)\n",
    "        k = 0\n",
    "        #Default values if we can't find anything to replace with\n",
    "        predMon = float('nan')\n",
    "        predDay = float('nan')\n",
    "        predYear = float('nan')\n",
    "        predHour = float('nan')\n",
    "        predMin = float('nan')\n",
    "        predSec = float('nan')   \n",
    "        \n",
    "        while k < len(df.columns):\n",
    "#             print(row[k], type(row[k]))\n",
    "            if type(row[k]) is object or type(row[k]) is str:\n",
    "#                 print(row)\n",
    "                m = 0\n",
    "                aMatch = False \n",
    "                while m < len(regexArr):\n",
    "                    match = re.match(regexArr[m], row[k])\n",
    "#                     print(match)\n",
    "                    if match is not None:\n",
    "#                         print(\"match\")\n",
    "#                         print(row[k])\n",
    "                        #partition data and append to tuple\n",
    "                        nonAlpha = re.findall('\\W+', row[k])\n",
    "#                         print(nonAlpha, row[k])\n",
    "                        dateData = row[k].split(nonAlpha[0])\n",
    "#                         print(dateData)\n",
    "                        count1 = 0\n",
    "                        count2 = 0\n",
    "                        count3 = 0\n",
    "                        dateData[0] = int(dateData[0])\n",
    "                        dateData[1] = int(dateData[1])\n",
    "                        dateData[2] = int(dateData[2])\n",
    "                        temp1 = dateData[0]\n",
    "                        temp2 = dateData[1]\n",
    "                        temp3 = dateData[2]\n",
    "                         \n",
    "                            \n",
    "                        while(dateData[0]>0):\n",
    "                            count1=count1+1\n",
    "                            dateData[0]=dateData[0]//10\n",
    "                        while(dateData[1]>0):\n",
    "                            count2=count2+1\n",
    "                            dateData[1]=dateData[1]//10\n",
    "                        while(dateData[2]>0):\n",
    "                            count3=count3+1\n",
    "                            dateData[2]=dateData[2]//10\n",
    "                            \n",
    "                        dateData[0] = temp1\n",
    "                        dateData[1] = temp2\n",
    "                        dateData[2] = temp3\n",
    "                        if(count1 < 4 and count2 < 4 and count3 <4): #predicting to be time info\n",
    "                            predHour = dateData[0]\n",
    "                            predMin = dateData[1]\n",
    "                            predSec = dateData[2]\n",
    "                        else:#predicting to be date data\n",
    "#                             print(\"IN THE ELSE!!!!!!\")\n",
    "                            if dateData[0] in yearArr and (dateData[0] not in monthArr and dateData[0] not in dayArr ) :\n",
    "                                predYear = dateData[0]\n",
    "                                if dateData[1] in dayArr and dateData[1] not in monthArr:\n",
    "                                    predDay = dateData[1]\n",
    "                                    predMon = dateData[2]\n",
    "                                else:\n",
    "                                    predDay = dateData[2]\n",
    "                                    predMon = dateData[1]\n",
    "                            elif dateData[1] in yearArr and (dateData[1] not in monthArr and dateData[1] not in dayArr ):\n",
    "                                predYear = dateData[1]\n",
    "                                if dateData[0] in dayArr and dateData[2] not in monthArr:\n",
    "                                    predDay = dateData[0]\n",
    "                                    predMon = dateData[2]\n",
    "                                else:\n",
    "                                    predDay = dateData[2]\n",
    "                                    predMon = dateData[0]\n",
    "#                             elif dateData[2] in yearArr and (dateData[2] not in monthArr and dateData[2] not in dayArr ):\n",
    "                            else:\n",
    "                                predYear = dateData[2]\n",
    "                                if dateData[0] in dayArr and dateData[0] not in monthArr:\n",
    "                                    predDay = dateData[0]\n",
    "                                    predMon = dateData[1]\n",
    "                                else:\n",
    "                                    predDay = dateData[1]\n",
    "                                    predMon = dateData[0]\n",
    "                \n",
    "                        aMatch = True\n",
    "                        m = len(regexArr)\n",
    "                        break\n",
    "                    m = m + 1\n",
    "                    \n",
    "                if aMatch == False:\n",
    "                    nonAlpha = re.findall('\\W+', row[k])\n",
    "                    while len(nonAlpha) != 0:\n",
    "#                         print(nonAlpha)\n",
    "                        splitChar = leastFrequent(nonAlpha, len(nonAlpha))\n",
    "                        nonAlpha = remAll(nonAlpha, splitChar)\n",
    "                        split = row[k].split(splitChar[0])\n",
    "                        if len(split) == 3:\n",
    "#                             \"^[\\d]{1,2}/[\\d]{1,2}/[\\d]{4}$\"\n",
    "                            if split[0].isdigit() and split[1].isdigit() and split[2].isdigit():\n",
    "                                newReg = \"^[\\d]{\"\n",
    "                                count=0\n",
    "                                split[0] = int(split[0])\n",
    "                                split[1] = int(split[1])\n",
    "                                split[2] = int(split[2])\n",
    "                                while(split[0]>0):\n",
    "                                    count=count+1\n",
    "                                    split[0]=split[0]//10\n",
    "                                newReg = newReg + str(count) + \"}\" + splitChar\n",
    "                                count = 0\n",
    "                                while(split[1]>0):\n",
    "                                    count=count+1\n",
    "                                    split[1]=split[1]//10\n",
    "                                newReg = newReg + \"[\\d]{\" +str(count) + \"}\" + splitChar\n",
    "                                count = 0\n",
    "                                while(split[2]>0):\n",
    "                                    count=count+1\n",
    "                                    split[2]=split[2]//10\n",
    "                                newReg = newReg + \"[\\d]{\" +str(count) + \"}$\"\n",
    "                                regexArr.append(newReg)\n",
    "                    y = y  + 1\n",
    "\n",
    "#             In the off chance the data was organized that temporal features\n",
    "#             were there own columns, we can attempt to find them by viewing\n",
    "#             the feature names\n",
    "            if(str(colNames[k]).lower() == \"month\"):\n",
    "                predMon = colNames[k]\n",
    "            if(str(colNames[k]).lower() == \"year\"):\n",
    "                predYear = colNames[k]\n",
    "            if(str(colNames[k]).lower() == \"day\"):\n",
    "                predDay = colNames[k]\n",
    "            if(str(colNames[k]).lower() == \"hour\"):\n",
    "                predHour = colNames[k]\n",
    "            if(str(colNames[k]).lower() == \"minute\"):\n",
    "                predMin = colNames[k]\n",
    "            if(str(colNames[k]).lower() == \"second\"):\n",
    "                predSec = colNames[k]\n",
    "                \n",
    "            k = k + 1\n",
    "        #Add temporal information here\n",
    "#         print(\"&&&&&&&&&&&&&&\", predYear)\n",
    "        predMonArr.append(predMon)\n",
    "        predDayArr.append(predDay)\n",
    "        predYearArr.append(predYear)\n",
    "        predHourArr.append(predHour)\n",
    "        predMinArr.append(predMin)\n",
    "        predSecArr.append(predSec)\n",
    "    i = i + 1  \n",
    "#     print((predMonArr))\n",
    "#     print((predDayArr))\n",
    "#     print((predYearArr))\n",
    "#     print((predHourArr))\n",
    "#     print((predMinArr))\n",
    "#     print((predSecArr))\n",
    "#     print(df.shape)\n",
    "    df[\"Predicted_Month\"] = predMonArr\n",
    "    df[\"Predicted_Day\"] = predDayArr\n",
    "    df[\"Predicted_Year\"] = predYearArr\n",
    "    df[\"Predicted_Hour\"] = predHourArr\n",
    "    df[\"Predicted_Minute\"] = predMinArr\n",
    "    df[\"Predicted_Second\"] = predSecArr\n",
    "\n",
    "# print(\"****\", regexArr)\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import geo locater\n",
    "from geopy.geocoders import Nominatim\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chicago, Cook County, Illinois, USA\n",
      "Chicago, Cook County, Illinois, USA\n",
      "(41.8755616, -87.6244212)\n",
      "{'place_id': '197578857', 'licence': 'Data Â© OpenStreetMap contributors, ODbL 1.0. https://osm.org/copyright', 'osm_type': 'relation', 'osm_id': '122604', 'boundingbox': ['41.643919', '42.0230219', '-87.940101', '-87.5239841'], 'lat': '41.8755616', 'lon': '-87.6244212', 'display_name': 'Chicago, Cook County, Illinois, USA', 'class': 'place', 'type': 'city', 'importance': 0.9826476104888859, 'icon': 'https://nominatim.openstreetmap.org/images/mapicons/poi_place_city.p.20.png'}\n"
     ]
    }
   ],
   "source": [
    "#quick example to play test with geolocater\n",
    "geolocator = Nominatim(user_agent=\"my586App\")\n",
    "location = geolocator.geocode(\"canal chicago il\")\n",
    "print(location)\n",
    "print(location.address)\n",
    "print((location.latitude, location.longitude))\n",
    "print(location.raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Josue\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "C:\\Users\\Josue\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "#searching for spatial information\n",
    "#Ideally attempt to find a direct address or name of item\n",
    "predXArr = []\n",
    "predYArr = []\n",
    "geolocator = Nominatim(user_agent=\"my586App\")\n",
    "i = 0\n",
    "defaultLoc = geolocator.geocode(\"chicago il\")\n",
    "while i < len(dfs):\n",
    "    predXArr = []\n",
    "    predYArr = []\n",
    "#     print(\"**********\")\n",
    "    df = dfs[i]\n",
    "    j = 0\n",
    "    k = 0\n",
    "    colNames = df.columns.values\n",
    "#     print(colNames)\n",
    "    for index, row in df.iterrows():\n",
    "        #deafult value if nothing is found\n",
    "\n",
    "        predX = defaultLoc.latitude\n",
    "        predY = defaultLoc.longitude\n",
    "        while k < len(df.columns):\n",
    "#             print(df.columns[k])\n",
    "#             print(df.columns[k], row[k])\n",
    "            if str(df.columns[k]).lower().find(\"address\") != -1:\n",
    "                location = geolocator.geocode(row[k], timeout=60)\n",
    "                if location != None:\n",
    "                    predX = location.latitude\n",
    "                    predY = location.longitude\n",
    "                    break\n",
    "            elif str(df.columns[k]).lower().find(\"location\") != -1:\n",
    "                location = geolocator.geocode(row[k], timeout=60)\n",
    "                if location != None:\n",
    "                    predX = location.latitude\n",
    "                    predY = location.longitude\n",
    "                    break\n",
    "            elif str(df.columns[k]).lower().find(\"name\") != -1:\n",
    "                loc = str(row[k]) + \" chicago il\"\n",
    "                location = geolocator.geocode(loc, timeout=60)\n",
    "                if location != None:\n",
    "                    predX = location.latitude\n",
    "                    predY = location.longitude\n",
    "                    break\n",
    "            elif str(df.columns[k]).lower().find(\"street\") != -1:\n",
    "                loc = str(row[k]) + \" chicago il\"\n",
    "                location = geolocator.geocode(loc, timeout=60)\n",
    "                if location != None:\n",
    "                    predX = location.latitude\n",
    "                    predY = location.longitude\n",
    "                    break\n",
    "            elif str(df.columns[k]).lower().find(\"zip\") != -1:\n",
    "                loc = str(row[k]) + \" chicago il\"\n",
    "                location = geolocator.geocode(loc, timeout=60)\n",
    "                if location != None:\n",
    "                    predX = location.latitude\n",
    "                    predY = location.longitude\n",
    "                    break\n",
    "\n",
    "            k = k + 1\n",
    "        time.sleep(.5)\n",
    "        predXArr.append(predX)\n",
    "        predYArr.append(predY)\n",
    "    \n",
    "    df[\"Predicted_X\"] = predXArr\n",
    "    df[\"Predicted_Y\"] = predYArr\n",
    "#     print(predXArr)\n",
    "#     print(predYArr)\n",
    "    i = i + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************************\n",
      "None\n",
      "******************************************\n",
      "None\n",
      "******************************************\n",
      "None\n",
      "******************************************\n",
      "None\n",
      "******************************************\n",
      "None\n",
      "******************************************\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Convert to JSON files\n",
    "i = 0\n",
    "names = [\"Building_Permits\", \"Libraries_-_Locations__Hours_and_Contact_Information_-_Map\", \"Green_Roofs_-_Map\", \"Chicago_Park_District__Movies_in_the_Parks_2017\", \"Towed_Vehicles\", \"Public_Health_Department_Events_-_For_LGBTQ\"]\n",
    "while i < len(dfs):\n",
    "    df = dfs[i]\n",
    "    print(\"******************************************\")\n",
    "    path = \"\"\n",
    "    path = path + names[i] + \".JSON\"\n",
    "    print(df.to_json(path, orient='table'))\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
